"""add_detected_at_to_events

Revision ID: 87c2226ce044
Revises: p1q2r3s4t5u6
Create Date: 2025-11-17 07:35:53.070202

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '87c2226ce044'
down_revision: Union[str, Sequence[str], None] = 'p1q2r3s4t5u6'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('context_signals',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('ticker', sa.String(), nullable=False),
    sa.Column('source', sa.String(), nullable=False),
    sa.Column('signal_type', sa.String(), nullable=False),
    sa.Column('severity', sa.Integer(), nullable=False),
    sa.Column('description', sa.Text(), nullable=False),
    sa.Column('observed_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_context_signals_id'), 'context_signals', ['id'], unique=False)
    op.create_index(op.f('ix_context_signals_observed_at'), 'context_signals', ['observed_at'], unique=False)
    op.create_index('ix_context_signals_source', 'context_signals', ['source'], unique=False)
    op.create_index('ix_context_signals_ticker', 'context_signals', ['ticker'], unique=False)
    op.drop_table('sessions')
    op.drop_table('verification_tokens')
    op.drop_table('email_waitlist')
    op.drop_constraint(op.f('alert_logs_alert_id_fkey'), 'alert_logs', type_='foreignkey')
    op.create_foreign_key(None, 'alert_logs', 'alerts', ['alert_id'], ['id'], ondelete='CASCADE')
    op.alter_column('companies', 'id',
               existing_type=sa.INTEGER(),
               server_default=None,
               existing_nullable=False,
               autoincrement=True)
    op.alter_column('event_outcomes', 'return_pct_raw',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               comment=None,
               existing_comment='Raw stock return (before benchmark adjustment)',
               existing_nullable=True)
    op.alter_column('event_outcomes', 'benchmark_return_pct',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               comment=None,
               existing_comment='SPY benchmark return for same period',
               existing_nullable=True)
    op.alter_column('event_outcomes', 'return_pct',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               comment=None,
               existing_comment='Abnormal return (stock return - benchmark return) - PRIMARY ML TARGET',
               existing_nullable=False)
    op.alter_column('event_outcomes', 'has_benchmark_data',
               existing_type=sa.BOOLEAN(),
               nullable=True,
               comment=None,
               existing_comment='True if SPY benchmark data was available',
               existing_server_default=sa.text('false'))
    op.alter_column('event_scores', 'ml_confidence',
               existing_type=sa.INTEGER(),
               type_=sa.Float(),
               existing_nullable=True)
    op.create_index(op.f('ix_event_scores_id'), 'event_scores', ['id'], unique=False)
    op.drop_constraint(op.f('event_scores_event_id_fkey'), 'event_scores', type_='foreignkey')
    op.create_foreign_key(None, 'event_scores', 'events', ['event_id'], ['id'])
    op.add_column('events', sa.Column('detected_at', sa.DateTime(timezone=True), nullable=True))
    op.alter_column('events', 'id',
               existing_type=sa.INTEGER(),
               server_default=None,
               existing_nullable=False,
               autoincrement=True)
    op.alter_column('events', 'source',
               existing_type=sa.VARCHAR(),
               nullable=False)
    op.alter_column('events', 'impact_score_version',
               existing_type=sa.INTEGER(),
               nullable=True,
               existing_server_default=sa.text('1'))
    op.drop_index(op.f('idx_events_info_tier'), table_name='events')
    op.drop_index(op.f('idx_events_ticker'), table_name='events')
    op.drop_index(op.f('idx_events_ticker_date'), table_name='events')
    op.drop_index(op.f('ix_events_source_url_lower_unique'), table_name='events', postgresql_where='(source_url IS NOT NULL)')
    op.create_index(op.f('ix_events_date'), 'events', ['date'], unique=False)
    op.create_index(op.f('ix_events_detected_at'), 'events', ['detected_at'], unique=False)
    op.create_unique_constraint('uix_event_natural_key', 'events', ['ticker', 'event_type', 'raw_id'])
    op.drop_constraint(op.f('portfolio_positions_portfolio_id_fkey'), 'portfolio_positions', type_='foreignkey')
    op.create_foreign_key(None, 'portfolio_positions', 'user_portfolios', ['portfolio_id'], ['id'], ondelete='CASCADE')
    op.create_index(op.f('ix_scan_jobs_id'), 'scan_jobs', ['id'], unique=False)
    op.create_index(op.f('ix_scanner_logs_id'), 'scanner_logs', ['id'], unique=False)
    op.drop_constraint(op.f('users_stripe_customer_id_key'), 'users', type_='unique')
    op.alter_column('watchlist', 'id',
               existing_type=sa.INTEGER(),
               server_default=None,
               existing_nullable=False,
               autoincrement=True)
    op.drop_index(op.f('ix_watchlist_ticker'), table_name='watchlist')
    op.create_index(op.f('ix_watchlist_ticker'), 'watchlist', ['ticker'], unique=False)
    op.create_index(op.f('ix_watchlist_user_id'), 'watchlist', ['user_id'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_watchlist_user_id'), table_name='watchlist')
    op.drop_index(op.f('ix_watchlist_ticker'), table_name='watchlist')
    op.create_index(op.f('ix_watchlist_ticker'), 'watchlist', ['ticker'], unique=True)
    op.alter_column('watchlist', 'id',
               existing_type=sa.INTEGER(),
               server_default=sa.Identity(always=False, start=1, increment=1, minvalue=1, maxvalue=2147483647, cycle=False, cache=1),
               existing_nullable=False,
               autoincrement=True)
    op.create_unique_constraint(op.f('users_stripe_customer_id_key'), 'users', ['stripe_customer_id'], postgresql_nulls_not_distinct=False)
    op.drop_index(op.f('ix_scanner_logs_id'), table_name='scanner_logs')
    op.drop_index(op.f('ix_scan_jobs_id'), table_name='scan_jobs')
    op.drop_constraint(None, 'portfolio_positions', type_='foreignkey')
    op.create_foreign_key(op.f('portfolio_positions_portfolio_id_fkey'), 'portfolio_positions', 'user_portfolios', ['portfolio_id'], ['id'])
    op.drop_constraint('uix_event_natural_key', 'events', type_='unique')
    op.drop_index(op.f('ix_events_detected_at'), table_name='events')
    op.drop_index(op.f('ix_events_date'), table_name='events')
    op.create_index(op.f('ix_events_source_url_lower_unique'), 'events', [sa.literal_column('lower(source_url::text)')], unique=True, postgresql_where='(source_url IS NOT NULL)')
    op.create_index(op.f('idx_events_ticker_date'), 'events', ['ticker', sa.literal_column('date DESC')], unique=False)
    op.create_index(op.f('idx_events_ticker'), 'events', ['ticker'], unique=False)
    op.create_index(op.f('idx_events_info_tier'), 'events', ['info_tier'], unique=False)
    op.alter_column('events', 'impact_score_version',
               existing_type=sa.INTEGER(),
               nullable=False,
               existing_server_default=sa.text('1'))
    op.alter_column('events', 'source',
               existing_type=sa.VARCHAR(),
               nullable=True)
    op.alter_column('events', 'id',
               existing_type=sa.INTEGER(),
               server_default=sa.Identity(always=False, start=1, increment=1, minvalue=1, maxvalue=2147483647, cycle=False, cache=1),
               existing_nullable=False,
               autoincrement=True)
    op.drop_column('events', 'detected_at')
    op.drop_constraint(None, 'event_scores', type_='foreignkey')
    op.create_foreign_key(op.f('event_scores_event_id_fkey'), 'event_scores', 'events', ['event_id'], ['id'], ondelete='CASCADE')
    op.drop_index(op.f('ix_event_scores_id'), table_name='event_scores')
    op.alter_column('event_scores', 'ml_confidence',
               existing_type=sa.Float(),
               type_=sa.INTEGER(),
               existing_nullable=True)
    op.alter_column('event_outcomes', 'has_benchmark_data',
               existing_type=sa.BOOLEAN(),
               nullable=False,
               comment='True if SPY benchmark data was available',
               existing_server_default=sa.text('false'))
    op.alter_column('event_outcomes', 'return_pct',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               comment='Abnormal return (stock return - benchmark return) - PRIMARY ML TARGET',
               existing_nullable=False)
    op.alter_column('event_outcomes', 'benchmark_return_pct',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               comment='SPY benchmark return for same period',
               existing_nullable=True)
    op.alter_column('event_outcomes', 'return_pct_raw',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               comment='Raw stock return (before benchmark adjustment)',
               existing_nullable=True)
    op.alter_column('companies', 'id',
               existing_type=sa.INTEGER(),
               server_default=sa.Identity(always=False, start=1, increment=1, minvalue=1, maxvalue=2147483647, cycle=False, cache=1),
               existing_nullable=False,
               autoincrement=True)
    op.drop_constraint(None, 'alert_logs', type_='foreignkey')
    op.create_foreign_key(op.f('alert_logs_alert_id_fkey'), 'alert_logs', 'alerts', ['alert_id'], ['id'])
    op.create_table('email_waitlist',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('email', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('email_waitlist_pkey')),
    sa.UniqueConstraint('email', name=op.f('email_waitlist_email_key'), postgresql_include=[], postgresql_nulls_not_distinct=False)
    )
    op.create_table('verification_tokens',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('code_hash', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('expires_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('consumed_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('attempts', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name=op.f('verification_tokens_user_id_fkey'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('verification_tokens_pkey'))
    )
    op.create_table('sessions',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('token', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('expires_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name=op.f('sessions_user_id_fkey'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('sessions_pkey')),
    sa.UniqueConstraint('token', name=op.f('sessions_token_key'), postgresql_include=[], postgresql_nulls_not_distinct=False)
    )
    op.drop_index('ix_context_signals_ticker', table_name='context_signals')
    op.drop_index('ix_context_signals_source', table_name='context_signals')
    op.drop_index(op.f('ix_context_signals_observed_at'), table_name='context_signals')
    op.drop_index(op.f('ix_context_signals_id'), table_name='context_signals')
    op.drop_table('context_signals')
    # ### end Alembic commands ###
